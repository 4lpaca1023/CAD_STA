# Benchmark Harness Overview

This directory bundles the scripts and collateral that drive the STA tool comparisons. The most important entry points are summarized below.

## `run_all.sh`
**現在只能從這裡執行腳本**
- Orchestrates a full benchmark sweep. Every invocation reads `tool_paths.env`, resolves the selected design manifest, and runs OpenSTA (batch + interactive), OpenTimer (batch + interactive), and iEDA/iSTA.
- Results are written to `results/run_<timestamp>/`. Each run directory contains per-tool subfolders (`OpenSTA_batch/`, `.../iEDA_iSTA/`), a `run_info.txt` manifest that lists the design inputs that were used, and a `summary.txt` generated by `scripts/summarize_results.py`.
- Usage: `./run_all.sh` from `benchmark/`. Adjust `BENCHMARK_DESIGN` in `tool_paths.env` to switch designs or edit the manifest under `designs/<name>/design.env` for custom inputs.

## `.env` (`tool_paths.env`)
- Stores the paths to each STA binary (`OPENSTA_BIN`, `OPENTIMER_BIN`, `ISTA_BIN`, `TATUM_BIN`). Relative paths are resolved against the repo root.
- Holds `BENCHMARK_DESIGN`, which points to a folder under `designs/`. Each design folder contains a `design.env` file with the top module name, netlist/SDC/SPEF filenames, and the Liberty pair to use. Update this file whenever you add a new design or relocate a binary.

## STA driver scripts
**現在不能單獨執行腳本，變數需要在run_all.sh設定（或使用下方的環境設定腳本）**
- `scripts/opensta_batch.tcl` / `scripts/opensta_interactive_commands.tcl`: lightweight wrappers that source `opensta_common.tcl`. The shared script consumes the `BENCHMARK_*` variables provided by `run_all.sh`, reads all design collateral, and emits `report_checks`, `report_tns`, and `report_wns`.
- `scripts/opentimer_batch.ot`: a template rendered by `run_all.sh` via `envsubst`. It mirrors the OpenSTA flow (load Liberty/Verilog/SDC/SPEF, enable CPPR, run `report_timing`, `report_tns`, and `report_wns`). You can run it manually with `ot-shell --stdin` after exporting the same `BENCHMARK_*` variables.
- `scripts/ista_simple.tcl`: drives iEDA/iSTA. It loads the design workspace specified by `BENCHMARK_RESULT_DIR`, reads the netlist/lib/SDC/SPEF, and prints both `-delay_type max` and `min` timing reports.
- `scripts/setup_benchmark_env.sh`：快速載入 `tool_paths.env` 和目標 `design.env`，自動匯出所有 `BENCHMARK_*` 變數。執行一次後即可手動呼叫上面三個 STA 腳本，不必整體跑 `run_all.sh`。建議 `source scripts/setup_benchmark_env.sh` 以便沿用環境。

## Additional utilities
- `scripts/summarize_results.py`: parses each tool’s `run.log`, extracts `/usr/bin/time` stats and the reported TNS/WNS values, and writes a consolidated summary. `run_all.sh` runs this automatically, but you can invoke it manually as `scripts/summarize_results.py results/run_<timestamp>`.
- `designs/<name>/`: each subfolder contains the raw benchmark inputs plus a `design.env` manifest. The default `simple` design mirrors the original OpenTimer example, while `gcd` imports the OpenSTA GCD test case.

## Design considerations / known issues
gcd 使用了更豐富 (richer)、但可攜性較低 (less portable) 的約束 (constraints) 和寄生參數 (parasitics)，只有OpenSTA可以直接執行
為了讓它能在所有工具上使用，您需要清理 (sanitize) 該資料集（例如：以 OpenTimer 接受的格式重新產生 SPEF、為 iSTA 將匯流排物件名稱扁平化 (flatten)、或可能修剪 (trim) 不被支援的 Liberty 屬性）。
(gcd是從openSTA抓出來的範例，simple是從openTimer抓出來的)
- `simple` is the most portable test case (scalar ports, minimal constraints, and short SPEF). All configured tools complete successfully.
- `gcd` originates from the OpenSTA sky130 demo and stresses the parsers:
  - OpenTimer aborts while reading `gcd_sky130hd.spef` (`clk I` entry + subsequent primary-output assertion). A preprocessing step or regenerated SPEF is required before OpenTimer can time this design.
  - iEDA/iSTA fails when the SDC applies `set_input_delay` to bus-style names such as `req_msg[*]` (object list reported as empty). The SDC must be rewritten (e.g., enumerate each bit) to avoid the fatal error.
- Until the data is sanitized, expect only OpenSTA to succeed on `gcd`. Keep these limitations in mind when switching `BENCHMARK_DESIGN` or interpreting run logs.

## Adding a new design
1. Create `designs/<new_design>/` and copy the Verilog/SDC/SPEF/Liberty files into it.
2. Add a `design.env` describing the top module and filenames (`DESIGN_TOP`, `DESIGN_NETLIST`, etc.).
3. Set `BENCHMARK_DESIGN=<new_design>` in `tool_paths.env`.
4. Re-run `./run_all.sh` to capture the new design’s results.

With these conventions, every run is reproducible, self-documented, and easy to compare via the generated summaries.
